{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Urban sounds using Deep Learning\n",
    "\n",
    "## 3 Model Training and Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Preprocessed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the preprocessed data from previous notebook\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "path = '../../panotti/Preproc/'\n",
    "train_path = os.path.join(path, 'Train')\n",
    "test_path = os.path.join(path, 'Test')\n",
    "class_names = sorted(os.listdir(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    class_names = sorted(os.listdir(data_dir))\n",
    "    nb_classes = len(class_names)\n",
    "    print(\"class_names = \",class_names)\n",
    "\n",
    "    for (dirpath, dirnames, filenames) in os.walk(os.path.join(data_dir, class_names[0])):\n",
    "        with np.load(os.path.join(data_dir, class_names[0], filenames[0])) as sample_file:\n",
    "            mel_dims = sample_file['melgram'].shape\n",
    "\n",
    "    total_load = 0\n",
    "    for classname in class_names:\n",
    "        files = os.listdir(os.path.join(data_dir, classname))\n",
    "        n_files = len(files)\n",
    "        total_load += n_files\n",
    "\n",
    "    print(\" melgram dimensions: \",mel_dims)\n",
    "    X = np.zeros((total_load, mel_dims[1], mel_dims[2], mel_dims[3]))\n",
    "    Y = np.zeros((total_load, nb_classes))\n",
    "    paths = []\n",
    "\n",
    "    load_count = 0\n",
    "    num_classes = len(class_names)\n",
    "    label_smoothing = 0.005\n",
    "\n",
    "    for idx, classname in enumerate(class_names):\n",
    "\n",
    "        idx = class_names.index(classname)\n",
    "        vec = np.zeros(num_classes)\n",
    "        vec[idx] = 1\n",
    "        vec = vec * (1 - label_smoothing) + label_smoothing / num_classes\n",
    "\n",
    "        this_Y = np.array(vec)\n",
    "        this_Y = this_Y[np.newaxis,:]\n",
    "        file_list = os.listdir(os.path.join(data_dir, classname))\n",
    "        shuffle(file_list)  # just to remove any special ordering\n",
    "\n",
    "        for _, infilename in enumerate(file_list):   # Load files in a particular class\n",
    "            audio_path = os.path.join(data_dir, classname, infilename)\n",
    "\n",
    "            with np.load(audio_path) as data:\n",
    "                melgram = data['melgram']\n",
    "            if melgram.shape != mel_dims:\n",
    "                raise Error('Dimension mismatch')\n",
    "\n",
    "            # usually it's the 2nd dimension of melgram.shape that is affected by audio file length\n",
    "            X[load_count,:,:] = melgram[:,:,:]\n",
    "            #X[load_count,:,:] = melgram\n",
    "            Y[load_count,:] = this_Y\n",
    "            paths.append(audio_path)\n",
    "            load_count += 1\n",
    "        print('Successfully processed {} files for class {}'\n",
    "              .format(len(file_list), classname))\n",
    "\n",
    "\n",
    "    assert (X.shape[0] == Y.shape[0] )\n",
    "    #print(\"shuffle_XY_paths: Y.shape[0], len(paths) = \",Y.shape[0], len(paths))\n",
    "    idx = np.array(range(Y.shape[0]))\n",
    "    np.random.shuffle(idx)\n",
    "    newX = np.copy(X)\n",
    "    newY = np.copy(Y)\n",
    "    for i in range(len(idx)):\n",
    "        newX[i] = X[idx[i],:,:]\n",
    "        newY[i] = Y[idx[i],:]\n",
    "\n",
    "    return newX, newY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names =  ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n",
      " melgram dimensions:  (1, 96, 87, 1)\n",
      "Successfully processed 1368 files for class bed\n",
      "Successfully processed 1384 files for class bird\n",
      "Successfully processed 1386 files for class cat\n",
      "Successfully processed 1396 files for class dog\n",
      "Successfully processed 1887 files for class down\n",
      "Successfully processed 1881 files for class eight\n",
      "Successfully processed 1885 files for class five\n",
      "Successfully processed 1897 files for class four\n",
      "Successfully processed 1897 files for class go\n",
      "Successfully processed 1393 files for class happy\n",
      "Successfully processed 1400 files for class house\n",
      "Successfully processed 1882 files for class left\n",
      "Successfully processed 1396 files for class marvin\n",
      "Successfully processed 1891 files for class nine\n",
      "Successfully processed 1900 files for class no\n",
      "Successfully processed 1885 files for class off\n",
      "Successfully processed 1893 files for class on\n",
      "Successfully processed 1896 files for class one\n",
      "Successfully processed 1893 files for class right\n",
      "Successfully processed 1901 files for class seven\n",
      "Successfully processed 1387 files for class sheila\n",
      "Successfully processed 1895 files for class six\n",
      "Successfully processed 1904 files for class stop\n",
      "Successfully processed 1884 files for class three\n",
      "Successfully processed 1386 files for class tree\n",
      "Successfully processed 1898 files for class two\n",
      "Successfully processed 1900 files for class up\n",
      "Successfully processed 1396 files for class wow\n",
      "Successfully processed 1901 files for class yes\n",
      "Successfully processed 1900 files for class zero\n",
      "class_names =  ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n",
      " melgram dimensions:  (1, 96, 87, 1)\n",
      "Successfully processed 343 files for class bed\n",
      "Successfully processed 347 files for class bird\n",
      "Successfully processed 347 files for class cat\n",
      "Successfully processed 350 files for class dog\n",
      "Successfully processed 472 files for class down\n",
      "Successfully processed 471 files for class eight\n",
      "Successfully processed 472 files for class five\n",
      "Successfully processed 475 files for class four\n",
      "Successfully processed 475 files for class go\n",
      "Successfully processed 349 files for class happy\n",
      "Successfully processed 350 files for class house\n",
      "Successfully processed 471 files for class left\n",
      "Successfully processed 350 files for class marvin\n",
      "Successfully processed 473 files for class nine\n",
      "Successfully processed 475 files for class no\n",
      "Successfully processed 472 files for class off\n",
      "Successfully processed 474 files for class on\n",
      "Successfully processed 474 files for class one\n",
      "Successfully processed 474 files for class right\n",
      "Successfully processed 476 files for class seven\n",
      "Successfully processed 347 files for class sheila\n",
      "Successfully processed 474 files for class six\n",
      "Successfully processed 476 files for class stop\n",
      "Successfully processed 472 files for class three\n",
      "Successfully processed 347 files for class tree\n",
      "Successfully processed 475 files for class two\n",
      "Successfully processed 475 files for class up\n",
      "Successfully processed 349 files for class wow\n",
      "Successfully processed 476 files for class yes\n",
      "Successfully processed 476 files for class zero\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, Y_train = load_data(train_path)\n",
    "X_test, Y_test = load_data(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial model architecture - MLP\n",
    "\n",
    "We will start with constructing a Multilayer Perceptron (MLP) Neural Network using Keras and a Tensorflow backend. \n",
    "\n",
    "Starting with a `sequential` model so we can build the model layer by layer. \n",
    "\n",
    "We will begin with a simple model architecture, consisting of three layers, an input layer, a hidden layer and an output layer. All three layers will be of the `dense` layer type which is a standard layer type that is used in many cases for neural networks. \n",
    "\n",
    "The first layer will receive the input shape. As each sample contains 40 MFCCs (or columns) we have a shape of (1x40) this means we will start with an input shape of 40. \n",
    "\n",
    "The first two layers will have 256 nodes. The activation function we will be using for our first 2 layers is the `ReLU`, or `Rectified Linear Activation`. This activation function has been proven to work well in neural networks.\n",
    "\n",
    "We will also apply a `Dropout` value of 50% on our first two layers. This will randomly exclude nodes from each update cycle which in turn results in a network that is capable of better generalisation and is less likely to overfit the training data.\n",
    "\n",
    "Our output layer will have 10 nodes (num_labels) which matches the number of possible classifications. The activation is for our output layer is `softmax`. Softmax makes the output sum up to 1 so the output can be interpreted as probabilities. The model will then make its prediction based on which option has the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CNN: X_shape =  (51762, 96, 87, 1) , channels =  1\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential,  load_model, save_model\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "nb_layers=4\n",
    "# Here's where one might 'swap out' different neural network 'model' choices\n",
    "K.set_image_data_format('channels_last')                   # SHH changed on 3/1/2018 b/c tensorflow prefers channels_last\n",
    "\n",
    "nb_filters = 32  # number of convolutional filters = \"feature maps\"\n",
    "kernel_size = (3, 3)  # convolution kernel size\n",
    "pool_size = (2, 2)  # size of pooling area for max pooling\n",
    "cl_dropout = 0.5    # conv. layer dropout\n",
    "dl_dropout = 0.6    # dense layer dropout\n",
    "X_shape = X_train.shape\n",
    "\n",
    "print(\" CNN: X_shape = \",X_shape,\", channels = \",X_shape[3])\n",
    "input_shape = (X_shape[1], X_shape[2], X_shape[3])\n",
    "model = Sequential()\n",
    "model.add(Conv2D(nb_filters, kernel_size, padding='same', input_shape=input_shape, name=\"Input\"))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Activation('relu'))        # Leave this relu & BN here.  ELU is not good here (my experience)\n",
    "model.add(BatchNormalization(axis=-1))  # axis=1 for 'channels_first'; but tensorflow preferse channels_last (axis=-1)\n",
    "\n",
    "for layer in range(nb_layers-1):   # add more layers than just the first\n",
    "    model.add(Conv2D(nb_filters, kernel_size, padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(cl_dropout))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))            # 128 is 'arbitrary' for now\n",
    "#model.add(Activation('relu'))   # relu (no BN) works ok here, however ELU works a bit better...\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(dl_dropout))\n",
    "model.add(Dense(len(class_names)))\n",
    "model.add(Activation(\"softmax\",name=\"Output\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model \n",
    "\n",
    "For compiling our model, we will use the following three parameters: \n",
    "\n",
    "* Loss function - we will use `categorical_crossentropy`. This is the most common choice for classification. A lower score indicates that the model is performing better.\n",
    "\n",
    "* Metrics - we will use the `accuracy` metric which will allow us to view the accuracy score on the validation data when we train the model. \n",
    "\n",
    "* Optimizer - here we will use `adam` which is a generally good optimizer for many use cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (Conv2D)               (None, 96, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 48, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 48, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 48, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 24, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 24, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 24, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 21, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 12, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 6, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 6, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               123008    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                3870      \n",
      "_________________________________________________________________\n",
      "Output (Activation)          (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 155,070\n",
      "Trainable params: 155,006\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Loding Weights from file weights.hdf5\n",
      "Train on 41408 samples, validate on 10353 samples\n",
      "Epoch 1/2\n",
      "41408/41408 [==============================] - 159s 4ms/step - loss: 1.0386 - accuracy: 0.7076 - val_loss: 0.4644 - val_accuracy: 0.8830\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46442, saving model to weights.hdf5\n",
      "Epoch 2/2\n",
      "41408/41408 [==============================] - 171s 4ms/step - loss: 1.0092 - accuracy: 0.7152 - val_loss: 0.4719 - val_accuracy: 0.8816\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.46442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb5c77d0c88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.models import load_model\n",
    "\n",
    "# Display model architecture summary \n",
    "val_split = 0.2\n",
    "split_index = int(X_train.shape[0]*(1-val_split))\n",
    "X_val_data, Y_val_data = X_train[split_index:], Y_train[split_index:]\n",
    "X_train_data, Y_train_data = X_train[:split_index-1], Y_train[:split_index-1]\n",
    "weights_file='weights.hdf5'\n",
    "\n",
    "if os.path.isfile(weights_file):\n",
    "    loaded_model = load_model(weights_file)   # strip any previous parallel part, to be added back in later\n",
    "    model.set_weights( loaded_model.get_weights() )  \n",
    "    print('Loading Weights from file {}'.format(weights_file))\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=weights_file, \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(X_train_data, Y_train_data, batch_size=32, epochs=2, shuffle=True,  callbacks=[checkpointer],\n",
    "              verbose=1, validation_data=(X_val_data, Y_val_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "\n",
    "Here we will train the model. \n",
    "\n",
    "We will start with 100 epochs which is the number of times the model will cycle through the data. The model will improve on each cycle until it reaches a certain point. \n",
    "\n",
    "We will also start with a low batch size, as having a large batch size can reduce the generalisation ability of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model \n",
    "\n",
    "Here we will review the accuracy of the model on both the training and test data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8819790482521057\n",
      "Testing Accuracy:  0.8679478168487549\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, Y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial Training and Testing accuracy scores are quite high. As there is not a great difference between the Training and Test scores (~5%) this suggests that the model has not suffered from overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions  \n",
    "\n",
    "Here we will build a method which will allow us to test the models predictions on a specified audio .wav file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "y = np.array(class_names)\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import numpy as np \n",
    "\n",
    "def extract_melgram(file_name):\n",
    "    signal, sr = librosa.load(file_name, mono=False, sr=44100)\n",
    "    if len(signal.shape) == 1:\n",
    "        signal = np.reshape(signal, (1, signal.shape[0]))\n",
    "    melgram = librosa.amplitude_to_db(librosa.feature.melspectrogram(signal[0], sr=sr, n_mels=96))[np.newaxis,:,:,np.newaxis] \n",
    "    melgram = melgram.astype(np.float16)\n",
    "    return  melgram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_melgram(file_name) \n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation \n",
    "\n",
    "#### Test with sample data \n",
    "\n",
    "Initial sainity check to verify the predictions using a subsection of the sample audio files we explored in the first notebook. We expect the bulk of these to be classified correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed \t\t :  0.00000004052580848679099290166050\n",
      "bird \t\t :  0.00000000679806300141194697062019\n",
      "cat \t\t :  0.00000001439836516681225475622341\n",
      "dog \t\t :  0.00001661814894760027527809143066\n",
      "down \t\t :  0.00569163775071501731872558593750\n",
      "eight \t\t :  0.00000000772307551244466594653204\n",
      "five \t\t :  0.00000000219587259486786479101283\n",
      "four \t\t :  0.00000010190364463369405712001026\n",
      "go \t\t :  0.22750957310199737548828125000000\n",
      "happy \t\t :  0.00000000720958093225476659426931\n",
      "house \t\t :  0.00015906471526250243186950683594\n",
      "left \t\t :  0.00000000133494137966039261300466\n",
      "marvin \t\t :  0.00000006934050844620287534780800\n",
      "nine \t\t :  0.00000939214714890113100409507751\n",
      "no \t\t :  0.76590603590011596679687500000000\n",
      "off \t\t :  0.00000001844883712465161806903780\n",
      "on \t\t :  0.00000001816302130919211776927114\n",
      "one \t\t :  0.00000012959999651229736628010869\n",
      "right \t\t :  0.00000001137163607722868619021028\n",
      "seven \t\t :  0.00000001087525713927561810123734\n",
      "sheila \t\t :  0.00000016204155883769999491050839\n",
      "six \t\t :  0.00000000004255543487041713035524\n",
      "stop \t\t :  0.00000049483293196317390538752079\n",
      "three \t\t :  0.00000021038403019701945595443249\n",
      "tree \t\t :  0.00000012026023910038929898291826\n",
      "two \t\t :  0.00049231073353439569473266601562\n",
      "up \t\t :  0.00000000286631873791520774830133\n",
      "wow \t\t :  0.00002628742186061572283506393433\n",
      "yes \t\t :  0.00001909034108393825590610504150\n",
      "zero \t\t :  0.00016868203238118439912796020508\n"
     ]
    }
   ],
   "source": [
    "# Class: Air Conditioner\n",
    "\n",
    "filename = '../../googleData' + '/no/14_6c968bd9_nohash_2.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed \t\t :  0.00000000020194251826310960495903\n",
      "bird \t\t :  0.00000000030625743607792799139133\n",
      "cat \t\t :  0.00000000000002218492621867355213\n",
      "dog \t\t :  0.00000000000340034424228807807822\n",
      "down \t\t :  0.00000000000001644698950870136095\n",
      "eight \t\t :  0.00000000947302858378407108830288\n",
      "five \t\t :  0.00000050353168035144335590302944\n",
      "four \t\t :  0.00000000000704127728345937953236\n",
      "go \t\t :  0.00000000002691116426922768312124\n",
      "happy \t\t :  0.00000000000085788743730413896671\n",
      "house \t\t :  0.00000000039158967735097860440874\n",
      "left \t\t :  0.00000019342060397775640012696385\n",
      "marvin \t\t :  0.00000000025054236463262213874259\n",
      "nine \t\t :  0.00000090260050455981399863958359\n",
      "no \t\t :  0.00000000003136934115244294218883\n",
      "off \t\t :  0.00000000000012417260416511949339\n",
      "on \t\t :  0.00000000000309874261666953643157\n",
      "one \t\t :  0.00000027808297886622312944382429\n",
      "right \t\t :  0.99998676776885986328125000000000\n",
      "seven \t\t :  0.00000000000024133662733169525261\n",
      "sheila \t\t :  0.00000000000014602113463692278916\n",
      "six \t\t :  0.00000000377043996024895022856072\n",
      "stop \t\t :  0.00000000000015550156106346191276\n",
      "three \t\t :  0.00001132084980781655758619308472\n",
      "tree \t\t :  0.00000001273529903755843406543136\n",
      "two \t\t :  0.00000000000000137428575768992148\n",
      "up \t\t :  0.00000000000001844422204755943179\n",
      "wow \t\t :  0.00000000014617240751135796017479\n",
      "yes \t\t :  0.00000000014035614337437607446191\n",
      "zero \t\t :  0.00000000001465525444055426618206\n"
     ]
    }
   ],
   "source": [
    "# Class: Drilling\n",
    "\n",
    "filename = '../../googleData' + '/right/18_3411cf4b_nohash_0.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed \t\t :  0.00000000129506505519572101547965\n",
      "bird \t\t :  0.00000015873901304530591005459428\n",
      "cat \t\t :  0.00000000000703198653820291674776\n",
      "dog \t\t :  0.00000000003155511615893225041418\n",
      "down \t\t :  0.00000000005554279952635354788981\n",
      "eight \t\t :  0.00017474179912824183702468872070\n",
      "five \t\t :  0.00000039951615349309577140957117\n",
      "four \t\t :  0.00000026758473836707707960158587\n",
      "go \t\t :  0.00000000062846861048626578849507\n",
      "happy \t\t :  0.00000024444116775157453957945108\n",
      "house \t\t :  0.00000000154519030903799148291000\n",
      "left \t\t :  0.00000000021475429767825460203312\n",
      "marvin \t\t :  0.00000000352613094278808603121433\n",
      "nine \t\t :  0.00000319332457365817390382289886\n",
      "no \t\t :  0.00000000023936472248742290958035\n",
      "off \t\t :  0.00000000004671573544667850796941\n",
      "on \t\t :  0.00000043983840214423253200948238\n",
      "one \t\t :  0.00000025243829782084503676742315\n",
      "right \t\t :  0.00000413649104302749037742614746\n",
      "seven \t\t :  0.00000000091512836197793490100594\n",
      "sheila \t\t :  0.00000000920826259687146375654265\n",
      "six \t\t :  0.00000002026510514951951336115599\n",
      "stop \t\t :  0.00000000013531989417892020810541\n",
      "three \t\t :  0.89502197504043579101562500000000\n",
      "tree \t\t :  0.10479401051998138427734375000000\n",
      "two \t\t :  0.00000005086743115612080146092921\n",
      "up \t\t :  0.00000000001214017514988841028867\n",
      "wow \t\t :  0.00000000001098464982168811943097\n",
      "yes \t\t :  0.00000000009657567801024669051912\n",
      "zero \t\t :  0.00000002625181849680302548222244\n"
     ]
    }
   ],
   "source": [
    "# Class: Street music \n",
    "\n",
    "filename = '../../googleData2/three/23_38d78313_nohash_2.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed \t\t :  0.00000113291150682925945147871971\n",
      "bird \t\t :  0.00000210597454497474245727062225\n",
      "cat \t\t :  0.00000027005157221537956502288580\n",
      "dog \t\t :  0.00000000285830048518675994273508\n",
      "down \t\t :  0.00000016647804557123890845105052\n",
      "eight \t\t :  0.00528699019923806190490722656250\n",
      "five \t\t :  0.00000028968324272682366427034140\n",
      "four \t\t :  0.00000354614871866942849010229111\n",
      "go \t\t :  0.00000092270693130558356642723083\n",
      "happy \t\t :  0.00001443670316803036257624626160\n",
      "house \t\t :  0.00000026161319510720204561948776\n",
      "left \t\t :  0.00000000640821795627743995282799\n",
      "marvin \t\t :  0.00000010081701162789613590575755\n",
      "nine \t\t :  0.00000373409511666977778077125549\n",
      "no \t\t :  0.00000010192528065999795217067003\n",
      "off \t\t :  0.00000001023202589323091160622425\n",
      "on \t\t :  0.00000080969545024345279671251774\n",
      "one \t\t :  0.00000025621864097047364339232445\n",
      "right \t\t :  0.00000016550166037632152438163757\n",
      "seven \t\t :  0.00000018194423034856299636885524\n",
      "sheila \t\t :  0.00000962884769251104444265365601\n",
      "six \t\t :  0.00001014865756587823852896690369\n",
      "stop \t\t :  0.00000001954270345549957710318267\n",
      "three \t\t :  0.04420212656259536743164062500000\n",
      "tree \t\t :  0.94948446750640869140625000000000\n",
      "two \t\t :  0.00097101728897541761398315429688\n",
      "up \t\t :  0.00000000348311757214503359136870\n",
      "wow \t\t :  0.00000000920621001654353676713072\n",
      "yes \t\t :  0.00000034729183084891701582819223\n",
      "zero \t\t :  0.00000675301498631597496569156647\n"
     ]
    }
   ],
   "source": [
    "# Class: Car Horn \n",
    "\n",
    "filename = '../../googleData2' + '/tree/24_07363607_nohash_0.wav'\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations \n",
    "\n",
    "From this brief sanity check the model seems to predict well. One errror was observed whereby a car horn was incorrectly classifed as a dog bark. \n",
    "\n",
    "We can see from the per class confidence that this was quite a low score (43%). This allows follows our early observation that a dog bark and car horn are similar in spectral shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *In the next notebook we will refine our model*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
