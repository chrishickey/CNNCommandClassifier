{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Google Voice Commands Using CNN\n",
    "\n",
    "### Model Training and Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Preprocessed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the preprocessed data from the files you created in the last notebook \n",
    "# (Please complete the previous notebook first!!)\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "np.random.seed(1)\n",
    "# SET THIS TO THE DIRECTORY WHERE YOU CREATED THE PREPROCESSED FILES IN THE LAST NOTEBOOK !\n",
    "preprocessed_dir = '../Preproc'\n",
    "dir_name = '../googleData'\n",
    "train_path = os.path.join(preprocessed_dir, 'train')\n",
    "test_path = os.path.join(preprocessed_dir, 'test')\n",
    "class_names = sorted(os.listdir(train_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets make a function for loading all our preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    class_names = sorted(os.listdir(data_dir))\n",
    "    nb_classes = len(class_names)\n",
    "    print(\"class_names = \",class_names)\n",
    "\n",
    "    for (dirpath, dirnames, filenames) in os.walk(os.path.join(data_dir, class_names[0])):\n",
    "        with np.load(os.path.join(data_dir, class_names[0], filenames[0])) as sample_file:\n",
    "            mel_dims = sample_file['melgram'].shape\n",
    "\n",
    "    total_load = 0\n",
    "    for classname in class_names:\n",
    "        files = os.listdir(os.path.join(data_dir, classname))\n",
    "        n_files = len(files)\n",
    "        total_load += n_files\n",
    "\n",
    "    X = np.zeros((total_load, mel_dims[1], mel_dims[2], mel_dims[3]))\n",
    "    Y = np.zeros((total_load, nb_classes))\n",
    "    paths = []\n",
    "\n",
    "    load_count = 0\n",
    "    num_classes = len(class_names)\n",
    "    label_smoothing = 0.005\n",
    "\n",
    "    for idx, classname in enumerate(class_names):\n",
    "        # Vector smoothing means that some allowance is made for classes where the the files \n",
    "        idx = class_names.index(classname)\n",
    "        vec = np.zeros(num_classes)\n",
    "        vec[idx] = 1\n",
    "        vec = vec * (1 - label_smoothing) + label_smoothing / num_classes\n",
    "\n",
    "        this_Y = np.array(vec)\n",
    "        this_Y = this_Y[np.newaxis,:]\n",
    "        file_list = os.listdir(os.path.join(data_dir, classname))\n",
    "        shuffle(file_list)  # just to remove any special ordering\n",
    "\n",
    "        for _, infilename in enumerate(file_list):   # Load files in a particular class\n",
    "            audio_path = os.path.join(data_dir, classname, infilename)\n",
    "            with np.load(audio_path) as data:\n",
    "                melgram = data['melgram']\n",
    "            if melgram.shape != mel_dims:\n",
    "                raise Exception('Dimension mismatch {} vs {}'.format(melgram.shape, mel_dims))\n",
    "\n",
    "            # usually it's the 2nd dimension of melgram.shape that is affected by audio file length\n",
    "            X[load_count,:,:] = melgram[:,:,:]\n",
    "            #X[load_count,:,:] = melgram\n",
    "            Y[load_count,:] = this_Y\n",
    "            paths.append(audio_path)\n",
    "            load_count += 1\n",
    "        print('Successfully processed {} files for class {}'\n",
    "              .format(len(file_list), classname))\n",
    "\n",
    "\n",
    "\n",
    "    assert (X.shape[0] == Y.shape[0] )\n",
    "    # Shuffle the classes up \n",
    "    idx = np.array(range(Y.shape[0]))\n",
    "    np.random.shuffle(idx)\n",
    "    newX = np.copy(X)\n",
    "    newY = np.copy(Y)\n",
    "    for i in range(len(idx)):\n",
    "        newX[i] = X[idx[i],:,:]\n",
    "        newY[i] = Y[idx[i],:]\n",
    "\n",
    "    return newX, newY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's load both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names =  ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n",
      "Successfully processed 1456 files for class bed\n",
      "Successfully processed 1471 files for class bird\n",
      "Successfully processed 1473 files for class cat\n",
      "Successfully processed 1484 files for class dog\n",
      "Successfully processed 2005 files for class down\n",
      "Successfully processed 1999 files for class eight\n",
      "Successfully processed 2003 files for class five\n",
      "Successfully processed 2016 files for class four\n",
      "Successfully processed 2016 files for class go\n",
      "Successfully processed 1480 files for class happy\n",
      "Successfully processed 1487 files for class house\n",
      "Successfully processed 2000 files for class left\n",
      "Successfully processed 1484 files for class marvin\n",
      "Successfully processed 2009 files for class nine\n",
      "Successfully processed 2018 files for class no\n",
      "Successfully processed 2003 files for class off\n",
      "Successfully processed 2011 files for class on\n",
      "Successfully processed 2014 files for class one\n",
      "Successfully processed 2011 files for class right\n",
      "Successfully processed 2020 files for class seven\n",
      "Successfully processed 1473 files for class sheila\n",
      "Successfully processed 2013 files for class six\n",
      "Successfully processed 2023 files for class stop\n",
      "Successfully processed 2002 files for class three\n",
      "Successfully processed 1473 files for class tree\n",
      "Successfully processed 2017 files for class two\n",
      "Successfully processed 2018 files for class up\n",
      "Successfully processed 1483 files for class wow\n",
      "Successfully processed 2020 files for class yes\n",
      "Successfully processed 2019 files for class zero\n",
      "class_names =  ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n",
      "Successfully processed 257 files for class bed\n",
      "Successfully processed 260 files for class bird\n",
      "Successfully processed 260 files for class cat\n",
      "Successfully processed 262 files for class dog\n",
      "Successfully processed 354 files for class down\n",
      "Successfully processed 353 files for class eight\n",
      "Successfully processed 354 files for class five\n",
      "Successfully processed 356 files for class four\n",
      "Successfully processed 356 files for class go\n",
      "Successfully processed 262 files for class happy\n",
      "Successfully processed 263 files for class house\n",
      "Successfully processed 353 files for class left\n",
      "Successfully processed 262 files for class marvin\n",
      "Successfully processed 355 files for class nine\n",
      "Successfully processed 357 files for class no\n",
      "Successfully processed 354 files for class off\n",
      "Successfully processed 356 files for class on\n",
      "Successfully processed 356 files for class one\n",
      "Successfully processed 356 files for class right\n",
      "Successfully processed 357 files for class seven\n",
      "Successfully processed 261 files for class sheila\n",
      "Successfully processed 356 files for class six\n",
      "Successfully processed 357 files for class stop\n",
      "Successfully processed 354 files for class three\n",
      "Successfully processed 260 files for class tree\n",
      "Successfully processed 356 files for class two\n",
      "Successfully processed 357 files for class up\n",
      "Successfully processed 262 files for class wow\n",
      "Successfully processed 357 files for class yes\n",
      "Successfully processed 357 files for class zero\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, Y_train = load_data(train_path)\n",
    "X_test, Y_test = load_data(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial model architecture - CNN\n",
    "\n",
    "#### Describe archtecture here !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CNN: X_shape =  (55001, 96, 87, 1) , channels =  1\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential,  load_model, save_model\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "nb_layers=4\n",
    "K.set_image_data_format('channels_last')                   \n",
    "nb_filters = 32  # number of convolutional filters\n",
    "kernel_size = (3, 3)  # convolution kernel size\n",
    "pool_size = (2, 2)  # size of pooling area for max pooling\n",
    "cl_dropout = 0.5    # conv. layer \n",
    "dl_dropout = 0.6    # dense layer \n",
    "X_shape = X_train.shape\n",
    "\n",
    "print(\" CNN: X_shape = \",X_shape,\", channels = \",X_shape[3])\n",
    "input_shape = (X_shape[1], X_shape[2], X_shape[3])\n",
    "model = Sequential()\n",
    "model.add(Conv2D(nb_filters, kernel_size, padding='same', input_shape=input_shape, name=\"Input\"))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Activation('relu'))      \n",
    "model.add(BatchNormalization(axis=-1)) \n",
    "\n",
    "for layer in range(nb_layers-1):   # add more layers than just the first\n",
    "    model.add(Conv2D(nb_filters, kernel_size, padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(cl_dropout))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))   # 128 is 'arbitrary' for now\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(dl_dropout))\n",
    "model.add(Dense(len(class_names)))\n",
    "model.add(Activation(\"softmax\",name=\"Output\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model \n",
    "\n",
    "Next compile the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (Conv2D)               (None, 96, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 43, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 21, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               123008    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                3870      \n",
      "_________________________________________________________________\n",
      "Output (Activation)          (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 155,070\n",
      "Trainable params: 155,006\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model\n",
    "Here let's train the model. Since the train/test split was set by default to .85/.15; here setting the train/val split to .8/.2 results in a train/val/test split of roughly .7/.15/.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Loading Weights from file weights.hdf5\n",
      "Train on 43999 samples, validate on 11001 samples\n",
      "Epoch 1/1\n",
      "43999/43999 [==============================] - 185s 4ms/step - loss: 1.0245 - accuracy: 0.7112 - val_loss: 0.4495 - val_accuracy: 0.8870\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44947, saving model to weights.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f49d84b40f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.models import load_model\n",
    "\n",
    "# Display model architecture summary \n",
    "val_split = 0.2\n",
    "epochs = 20 # 100 (but since I have already trained the weights file I don't need to retrain.)\n",
    "# In order to retrain from scratch please delete the weights file and set the epochs to between 20 - 100\n",
    "batch_size = 32\n",
    "\n",
    "split_index = int(X_train.shape[0]*(1-val_split))\n",
    "X_val_data, Y_val_data = X_train[split_index:], Y_train[split_index:]\n",
    "X_train_data, Y_train_data = X_train[:split_index-1], Y_train[:split_index-1]\n",
    "weights_file='weights.hdf5'\n",
    "\n",
    "if os.path.isfile(weights_file):\n",
    "    loaded_model = load_model(weights_file)   # strip any previous parallel part, to be added back in later\n",
    "    model.set_weights( loaded_model.get_weights() )  \n",
    "    print('Loading Weights from file {}'.format(weights_file))\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=weights_file, \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(X_train_data, Y_train_data, batch_size=batch_size, epochs=epochs, shuffle=True,  callbacks=[checkpointer],\n",
    "              verbose=1, validation_data=(X_val_data, Y_val_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model \n",
    "\n",
    "Here we will review the accuracy of the model on both the training and test data sets (here the training data is a compination of both the Train + Val sets). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8839839100837708\n",
      "Testing Accuracy:  0.8819958567619324\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, Y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both training and test scores are quite high, suggesting the model has not overfit as there is little difference between the training and test models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions  \n",
    "\n",
    "Lets look closer as to what the model predicts, first set the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "y = np.array(class_names)\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function for creating mel spectrograms from wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import numpy as np \n",
    "\n",
    "def extract_melgram(file_name):\n",
    "    signal, sr = librosa.load(file_name, mono=False, sr=44100)\n",
    "    if len(signal.shape) == 1:\n",
    "        signal = np.reshape(signal, (1, signal.shape[0]))\n",
    "    melgram = librosa.amplitude_to_db(librosa.feature.melspectrogram(signal[0], sr=sr, n_mels=96))[np.newaxis,:,:,np.newaxis] \n",
    "    melgram = melgram.astype(np.float16)\n",
    "    return  melgram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function for predicting output from these wab files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_melgram(file_name) \n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration \n",
    "\n",
    "Now lets use these functions to examine presictions from the test dataset more closely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../googleData/no/692a88e6_nohash_3.wav\n",
      "bed \t\t :  0.00223922100849449634552001953125\n",
      "bird \t\t :  0.00001725627589621581137180328369\n",
      "cat \t\t :  0.01505586598068475723266601562500\n",
      "dog \t\t :  0.00310107436962425708770751953125\n",
      "down \t\t :  0.02027723938226699829101562500000\n",
      "eight \t\t :  0.00001779654667188879102468490601\n",
      "five \t\t :  0.00000670899407850811257958412170\n",
      "four \t\t :  0.00002002794280997477471828460693\n",
      "go \t\t :  0.07486108690500259399414062500000\n",
      "happy \t\t :  0.00003331612242618575692176818848\n",
      "house \t\t :  0.00132211972959339618682861328125\n",
      "left \t\t :  0.00196837517432868480682373046875\n",
      "marvin \t\t :  0.00008275819709524512290954589844\n",
      "nine \t\t :  0.00088627921650186181068420410156\n",
      "no \t\t :  0.72599422931671142578125000000000\n",
      "off \t\t :  0.00009011977090267464518547058105\n",
      "on \t\t :  0.00000164620576015295227989554405\n",
      "one \t\t :  0.00013527624832931905984878540039\n",
      "right \t\t :  0.00009317646618001163005828857422\n",
      "seven \t\t :  0.00000414102441936847753822803497\n",
      "sheila \t\t :  0.00024354067863896489143371582031\n",
      "six \t\t :  0.00000311382473228150047361850739\n",
      "stop \t\t :  0.00060830469010397791862487792969\n",
      "three \t\t :  0.00000656398788123624399304389954\n",
      "tree \t\t :  0.00001278072522836737334728240967\n",
      "two \t\t :  0.00034463711199350655078887939453\n",
      "up \t\t :  0.00002145126018149312585592269897\n",
      "wow \t\t :  0.00139106425922363996505737304688\n",
      "yes \t\t :  0.14994058012962341308593750000000\n",
      "zero \t\t :  0.00122017017565667629241943359375\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(dir_name, 'no/692a88e6_nohash_3.wav')\n",
    "print(filename)\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed \t\t :  0.00000000005373932202012987602302\n",
      "bird \t\t :  0.00000000016150072945642079957906\n",
      "cat \t\t :  0.00000000000003426013474110665979\n",
      "dog \t\t :  0.00000000000286886313316525587425\n",
      "down \t\t :  0.00000000000001943108997001005006\n",
      "eight \t\t :  0.00000000119927068276126647106139\n",
      "five \t\t :  0.00000014667800485312909586355090\n",
      "four \t\t :  0.00000000000474365208572025132128\n",
      "go \t\t :  0.00000000000629958368456029482729\n",
      "happy \t\t :  0.00000000000057845476455695155060\n",
      "house \t\t :  0.00000000034614636157392908444308\n",
      "left \t\t :  0.00000006975890443072785274125636\n",
      "marvin \t\t :  0.00000000016940375491270032171087\n",
      "nine \t\t :  0.00000012274681182589119998738170\n",
      "no \t\t :  0.00000000002718415076374824934646\n",
      "off \t\t :  0.00000000000013491657335600037992\n",
      "on \t\t :  0.00000000000101450738001357398943\n",
      "one \t\t :  0.00000028834296017521410249173641\n",
      "right \t\t :  0.99999737739562988281250000000000\n",
      "seven \t\t :  0.00000000000025691894358498279516\n",
      "sheila \t\t :  0.00000000000005280628365134099056\n",
      "six \t\t :  0.00000000825067303367177373729646\n",
      "stop \t\t :  0.00000000000001269838252018935798\n",
      "three \t\t :  0.00000197019608094706200063228607\n",
      "tree \t\t :  0.00000000271829336817575040186057\n",
      "two \t\t :  0.00000000000000017372378403411723\n",
      "up \t\t :  0.00000000000003687288240581190757\n",
      "wow \t\t :  0.00000000003305029513955837217054\n",
      "yes \t\t :  0.00000000022827964518690180284466\n",
      "zero \t\t :  0.00000000000318094942747260134297\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(dir_name, 'right/3411cf4b_nohash_0.wav')\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed \t\t :  0.00000000091373908439607021136908\n",
      "bird \t\t :  0.00000015808863906840997515246272\n",
      "cat \t\t :  0.00000000003889152194735956413751\n",
      "dog \t\t :  0.00000000011766207452801324961911\n",
      "down \t\t :  0.00000000045101211654241524229292\n",
      "eight \t\t :  0.00014037001528777182102203369141\n",
      "five \t\t :  0.00000026052680368593428283929825\n",
      "four \t\t :  0.00000009437886916430215933360159\n",
      "go \t\t :  0.00000000162623381427806634746958\n",
      "happy \t\t :  0.00000023225538825499825179576874\n",
      "house \t\t :  0.00000001037094410349936879356392\n",
      "left \t\t :  0.00000000011953595058233901227140\n",
      "marvin \t\t :  0.00000001342473687770961987553164\n",
      "nine \t\t :  0.00000135925870381470303982496262\n",
      "no \t\t :  0.00000000106144493194904043775750\n",
      "off \t\t :  0.00000000013119644259873552982754\n",
      "on \t\t :  0.00000017772620708456088323146105\n",
      "one \t\t :  0.00000031578147741129214409738779\n",
      "right \t\t :  0.00001458072165405610576272010803\n",
      "seven \t\t :  0.00000000266715938224137971701566\n",
      "sheila \t\t :  0.00000000899206220594805927248672\n",
      "six \t\t :  0.00000010286003515602715197019279\n",
      "stop \t\t :  0.00000000008390919903344951080726\n",
      "three \t\t :  0.98338967561721801757812500000000\n",
      "tree \t\t :  0.01645258627831935882568359375000\n",
      "two \t\t :  0.00000004344134652001230278983712\n",
      "up \t\t :  0.00000000008513471871918198985441\n",
      "wow \t\t :  0.00000000004768689262912850779230\n",
      "yes \t\t :  0.00000000024681201526988161276677\n",
      "zero \t\t :  0.00000001700876062216138961957768\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.join(dir_name, 'three/38d78313_nohash_2.wav')\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed \t\t :  0.00000319975993079424370080232620\n",
      "bird \t\t :  0.00001930228609126061201095581055\n",
      "cat \t\t :  0.00000363687104254495352506637573\n",
      "dog \t\t :  0.00000006687793785431495052762330\n",
      "down \t\t :  0.00000070542705543630290776491165\n",
      "eight \t\t :  0.02149184606969356536865234375000\n",
      "five \t\t :  0.00000228441126637335401028394699\n",
      "four \t\t :  0.00000434840012530912645161151886\n",
      "go \t\t :  0.00000290086109089315868914127350\n",
      "happy \t\t :  0.00022248228196986019611358642578\n",
      "house \t\t :  0.00000334329320139659103006124496\n",
      "left \t\t :  0.00000002116596853340979578206316\n",
      "marvin \t\t :  0.00000271320914180250838398933411\n",
      "nine \t\t :  0.00002837108877429272979497909546\n",
      "no \t\t :  0.00000049340195573677192442119122\n",
      "off \t\t :  0.00000002857737158024065138306469\n",
      "on \t\t :  0.00000057358249705430353060364723\n",
      "one \t\t :  0.00000194963467947673052549362183\n",
      "right \t\t :  0.00000688392583469976671040058136\n",
      "seven \t\t :  0.00000217399565372033976018428802\n",
      "sheila \t\t :  0.00001421337947249412536621093750\n",
      "six \t\t :  0.00013790704542770981788635253906\n",
      "stop \t\t :  0.00000023290840545087121427059174\n",
      "three \t\t :  0.23245508968830108642578125000000\n",
      "tree \t\t :  0.74433314800262451171875000000000\n",
      "two \t\t :  0.00124954222701489925384521484375\n",
      "up \t\t :  0.00000007225356313256270368583500\n",
      "wow \t\t :  0.00000003395433623154531233012676\n",
      "yes \t\t :  0.00000172178749835438793525099754\n",
      "zero \t\t :  0.00001070161943061975762248039246\n"
     ]
    }
   ],
   "source": [
    " filename = os.path.join(dir_name, 'tree/07363607_nohash_0.wav')\n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished \n",
    "\n",
    "Great job! If you made it this far you should have nearly 90% accuracy on both the training and validation data. Feel free to play around with individual and check the classification for files from the testset individually."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
